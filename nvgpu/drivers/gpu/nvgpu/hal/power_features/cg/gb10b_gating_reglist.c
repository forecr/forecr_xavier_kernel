// SPDX-License-Identifier: GPL-2.0-only OR MIT
// SPDX-FileCopyrightText: Copyright (c) 2014-2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.

// This file is autogenerated.  Do not edit.


#include <nvgpu/types.h>
#include <nvgpu/io.h>
#include <nvgpu/enabled.h>
#include <nvgpu/utils.h>
#include <nvgpu/static_analysis.h>

#include <nvgpu/gk20a.h>
#include <nvgpu/fifo.h>
#include <nvgpu/runlist.h>
#include "hal/power_features/cg/gating_reglist.h"
#include "gb10b_gating_reglist.h"

#define GATING_DESC_SIZE (u32)(sizeof(struct gating_desc))

/* slcg bus */
static const struct gating_desc gb10b_slcg_bus[] = {
};

/* slcg ce2 */
static const struct gating_desc gb10b_slcg_ce2[] = {
	{.addr = 0x00104204U, .prod = 0x00003000U, .disable = 0xfffffffeU},
};

/* slcg chiplet */
static const struct gating_desc gb10b_slcg_chiplet[] = {
	{.addr = 0x0010e07cU, .prod = 0x00000000U, .disable = 0x00000001U},
	{.addr = 0x008e4e7cU, .prod = 0x00000000U, .disable = 0x00000001U},
};

/* slcg fb */
static const struct gating_desc gb10b_slcg_fb[] = {
	{.addr = 0x001fa39cU, .prod = 0x00000000U, .disable = 0x000003feU},
};

/* slcg runlist*/
static const struct gating_desc gb10b_slcg_runlist[] = {
	{.addr = 0x00000054U, .prod = 0x00000000U, .disable = 0x0001fffeU},
};

/* slcg gr */
static const struct gating_desc gb10b_slcg_gr[] = {
	{.addr = 0x004041f4U, .prod = 0x00000000U, .disable = 0x1ffffffeU},
	{.addr = 0x0040c134U, .prod = 0x00180140U, .disable = 0x0003fffeU},
	{.addr = 0x0040c798U, .prod = 0x00000000U, .disable = 0x00000003U},
	{.addr = 0x00409894U, .prod = 0x00004000U, .disable = 0x0000fffeU},
	{.addr = 0x00406004U, .prod = 0x00000000U, .disable = 0x0001fffeU},
	{.addr = 0x00405864U, .prod = 0x00000000U, .disable = 0x000001feU},
	{.addr = 0x00405bf4U, .prod = 0x00000000U, .disable = 0x00000002U},
	{.addr = 0x004078c4U, .prod = 0x0000003aU, .disable = 0x000001feU},
	{.addr = 0x00405910U, .prod = 0xfffffff0U, .disable = 0xfffffffeU},
	{.addr = 0x00408044U, .prod = 0x00000000U, .disable = 0x00000ffeU},
	{.addr = 0x00407004U, .prod = 0x00000002U, .disable = 0x000001feU},
	{.addr = 0x0042f134U, .prod = 0x00180140U, .disable = 0x0003fffeU},
	{.addr = 0x0042f798U, .prod = 0x00000000U, .disable = 0x00000003U},
	{.addr = 0x00422894U, .prod = 0x00004000U, .disable = 0x0000fffeU},
	{.addr = 0x00420974U, .prod = 0x00000000U, .disable = 0x0001fffeU},
	{.addr = 0x00420e10U, .prod = 0xfffffffeU, .disable = 0xfffffffeU},
	{.addr = 0x0042089cU, .prod = 0x00000000U, .disable = 0x000003feU},
	{.addr = 0x0042149cU, .prod = 0x00000000U, .disable = 0x000003feU},
	{.addr = 0x00420504U, .prod = 0x00000000U, .disable = 0xfffffffeU},
	{.addr = 0x0042060cU, .prod = 0x00000000U, .disable = 0x000001feU},
	{.addr = 0x0042068cU, .prod = 0x00000000U, .disable = 0x0000007eU},
	{.addr = 0x0042071cU, .prod = 0x00000000U, .disable = 0x000003feU},
	{.addr = 0x00420388U, .prod = 0x00000000U, .disable = 0x00000001U},
	{.addr = 0x0042082cU, .prod = 0x00000000U, .disable = 0x0001fffeU},
	{.addr = 0x00420bc0U, .prod = 0x00000000U, .disable = 0x000001feU},
	{.addr = 0x00420c74U, .prod = 0xffffff80U, .disable = 0xfffffffeU},
	{.addr = 0x00420cf4U, .prod = 0xfffffff0U, .disable = 0xfffffffeU},
	{.addr = 0x00420d74U, .prod = 0xffffffe0U, .disable = 0xfffffffeU},
	{.addr = 0x00420f90U, .prod = 0xffffffe0U, .disable = 0xfffffffeU},
	{.addr = 0x00421024U, .prod = 0x000001feU, .disable = 0x000001feU},
	{.addr = 0x00424524U, .prod = 0x00000002U, .disable = 0x000000ffU},
	{.addr = 0x0042406cU, .prod = 0x00000100U, .disable = 0x00fffffeU},
	{.addr = 0x00424484U, .prod = 0x0003fff4U, .disable = 0x0003fffeU},
	{.addr = 0x0042448cU, .prod = 0xff31f304U, .disable = 0xfffffffeU},
	{.addr = 0x00424494U, .prod = 0x38700340U, .disable = 0x3ffffffeU},
	{.addr = 0x004244a4U, .prod = 0x00003ffeU, .disable = 0x00003ffeU},
	{.addr = 0x004244acU, .prod = 0x0001f800U, .disable = 0x0001fffeU},
	{.addr = 0x004244b4U, .prod = 0x00001d00U, .disable = 0x00001ffeU},
	{.addr = 0x00424244U, .prod = 0x00000008U, .disable = 0x0000000eU},
	{.addr = 0x0042424cU, .prod = 0x000001f8U, .disable = 0x000001feU},
	{.addr = 0x00424254U, .prod = 0x0000003cU, .disable = 0x0000003eU},
	{.addr = 0x0042425cU, .prod = 0x0000000cU, .disable = 0x0000000eU},
	{.addr = 0x00424264U, .prod = 0x0000018aU, .disable = 0x000001feU},
	{.addr = 0x0042427cU, .prod = 0x0000003cU, .disable = 0x0000003eU},
	{.addr = 0x00424284U, .prod = 0x0000000cU, .disable = 0x0000000eU},
	{.addr = 0x00424474U, .prod = 0x0000001eU, .disable = 0x0000001eU},
	{.addr = 0x004241a0U, .prod = 0x00000000U, .disable = 0x00000001U},
	{.addr = 0x00423e2cU, .prod = 0x00001fc0U, .disable = 0xfffffffeU},
	{.addr = 0x00423fecU, .prod = 0xfffffff0U, .disable = 0xfffffffeU},
	{.addr = 0x00423ed4U, .prod = 0xfffffff8U, .disable = 0xfffffffeU},
	{.addr = 0x0042381cU, .prod = 0x00000000U, .disable = 0x0001fffeU},
	{.addr = 0x00423878U, .prod = 0x00000000U, .disable = 0x0001fffeU},
	{.addr = 0x0042389cU, .prod = 0x00000000U, .disable = 0x0001fffeU},
	{.addr = 0x00423c1cU, .prod = 0x00000000U, .disable = 0x0001fffeU},
	{.addr = 0x00423c78U, .prod = 0x00000000U, .disable = 0x0001fffeU},
	{.addr = 0x00423c9cU, .prod = 0x00000000U, .disable = 0x0001fffeU},
};

/* slcg ltc */
static const struct gating_desc gb10b_slcg_ltc[] = {
	{.addr = 0x001c6050U, .prod = 0x00000000U, .disable = 0xfffffffeU},
	{.addr = 0x001c635cU, .prod = 0x00000000U, .disable = 0xfffffffeU},
};

/* slcg perf */
static const struct gating_desc gb10b_slcg_perf[] = {
	{.addr = 0x002b409cU, .prod = 0x00000000U, .disable = 0x80000000U},
	{.addr = 0x002b4090U, .prod = 0x00000000U, .disable = 0x80000000U},
	{.addr = 0x002b409cU, .prod = 0x00000000U, .disable = 0x80000000U},
	{.addr = 0x002b4090U, .prod = 0x00000000U, .disable = 0x80000000U},
	{.addr = 0x002a009cU, .prod = 0x00000000U, .disable = 0x80000000U},
	{.addr = 0x002a0090U, .prod = 0x00000000U, .disable = 0x80000000U},
	{.addr = 0x002aa09cU, .prod = 0x00000000U, .disable = 0x80000000U},
	{.addr = 0x002aa090U, .prod = 0x00000000U, .disable = 0x80000000U},
	{.addr = 0x002a409cU, .prod = 0x00000000U, .disable = 0x80000000U},
	{.addr = 0x002a4090U, .prod = 0x00000000U, .disable = 0x80000000U},
	{.addr = 0x002aa49cU, .prod = 0x00000000U, .disable = 0x80000000U},
	{.addr = 0x002aa490U, .prod = 0x00000000U, .disable = 0x80000000U},
	{.addr = 0x002b0844U, .prod = 0x00000000U, .disable = 0x00000001U},
	{.addr = 0x002b0844U, .prod = 0x00000000U, .disable = 0x00000001U},
	{.addr = 0x002b6c3cU, .prod = 0x00000000U, .disable = 0x00000001U},
};

/* slcg PriRing */
static const struct gating_desc gb10b_slcg_priring[] = {
	{.addr = 0x001200a8U, .prod = 0x00000000U, .disable = 0x00000001U},
	{.addr = 0x001200a8U, .prod = 0x00000000U, .disable = 0x00000001U},
};

/* slcg pmu */
static const struct gating_desc gb10b_slcg_pmu[] = {
	{.addr = 0x008f4134U, .prod = 0x001c0140U, .disable = 0x0003fffeU},
	{.addr = 0x008f5398U, .prod = 0x00000000U, .disable = 0x00000003U},
	{.addr = 0x008f4e74U, .prod = 0x00000000U, .disable = 0x0000000fU},
	{.addr = 0x008f6a74U, .prod = 0x00000400U, .disable = 0x00003ffeU},
};

/* slcg fbhub */
static const struct gating_desc gb10b_slcg_fbhub[] = {
	{.addr = 0x008a0114U, .prod = 0x00000000U, .disable = 0xfffffffeU},
};

/* slcg Xbar */
static const struct gating_desc gb10b_slcg_xbar[] = {
	{.addr = 0x0013c824U, .prod = 0x00000000U, .disable = 0x7ffffffeU},
	{.addr = 0x0013ebc8U, .prod = 0x00000000U, .disable = 0xfffffffeU},
	{.addr = 0x0013c924U, .prod = 0x00000000U, .disable = 0x7ffffffeU},
	{.addr = 0x0013cb84U, .prod = 0x00000000U, .disable = 0x1ffffffeU},
	{.addr = 0x0013cb8cU, .prod = 0x00000000U, .disable = 0x1ffffffeU},
};

/* slcg Hshub */
static const struct gating_desc gb10b_slcg_hshub[] = {
};

/* slcg Ctrl */
static const struct gating_desc gb10b_slcg_ctrl[] = {
	{.addr = 0x00b66a2cU, .prod = 0x00000000U, .disable = 0x00000006U},
};

/* slcg GSP */
static const struct gating_desc gb10b_slcg_gsp[] = {
	{.addr = 0x00110134U, .prod = 0x001c0140U, .disable = 0x0003fffeU},
	{.addr = 0x00111398U, .prod = 0x00000000U, .disable = 0x00000003U},
	{.addr = 0x00110674U, .prod = 0x00000000U, .disable = 0x0000000fU},
	{.addr = 0x0011083cU, .prod = 0x80000040U, .disable = 0xffffffffU},
};

/* slcg timer */
static const struct gating_desc gb10b_slcg_timer[] = {
	{.addr = 0x00009600U, .prod = 0x00000000U, .disable = 0x00000002U},
};

/* slcg rs_ctrl_fbp */
static const struct gating_desc gb10b_slcg_rs_ctrl_fbp[] = {
	{.addr = 0x00128048U, .prod = 0x00000000U, .disable = 0x00000003U},
	{.addr = 0x00121048U, .prod = 0x00000000U, .disable = 0x00000003U},
};

/* slcg rs_ctrl_gpc */
static const struct gating_desc gb10b_slcg_rs_ctrl_gpc[] = {
	{.addr = 0x00124048U, .prod = 0x00000000U, .disable = 0x00000003U},
	{.addr = 0x00120848U, .prod = 0x00000000U, .disable = 0x00000003U},
};

/* slcg rs_ctrl_sys */
static const struct gating_desc gb10b_slcg_rs_ctrl_sys[] = {
	{.addr = 0x00122048U, .prod = 0x00000000U, .disable = 0x00000003U},
	{.addr = 0x00038048U, .prod = 0x00000000U, .disable = 0x00000003U},
};

/* slcg rs_fbp */
static const struct gating_desc gb10b_slcg_rs_fbp[] = {
	{.addr = 0x00128250U, .prod = 0x00000001U, .disable = 0x000007ffU},
	{.addr = 0x00121250U, .prod = 0x00000001U, .disable = 0x000007ffU},
};

/* slcg rs_gpc */
static const struct gating_desc gb10b_slcg_rs_gpc[] = {
	{.addr = 0x00124250U, .prod = 0x00000001U, .disable = 0x000007ffU},
	{.addr = 0x00120a50U, .prod = 0x00000001U, .disable = 0x000007ffU},
};

/* slcg rs_sys */
static const struct gating_desc gb10b_slcg_rs_sys[] = {
	{.addr = 0x00122250U, .prod = 0x00000001U, .disable = 0x000007ffU},
	{.addr = 0x00038250U, .prod = 0x00000001U, .disable = 0x000007ffU},
};

/* blcg bus */
static const struct gating_desc gb10b_blcg_bus[] = {
};

/* blcg ce */
static const struct gating_desc gb10b_blcg_ce[] = {
	{.addr = 0x00104200U, .prod = 0x0000c244U, .disable = 0x00000000U},
};

/* blcg fb */
static const struct gating_desc gb10b_blcg_fb[] = {
	{.addr = 0x001fa398U, .prod = 0x00004242U, .disable = 0x00000000U},
};

/* blcg runlist */
static const struct gating_desc gb10b_blcg_runlist[] = {
	{.addr = 0x00000050U, .prod = 0x00004042U, .disable = 0x00000000U},
};

/* blcg gr */
static const struct gating_desc gb10b_blcg_gr[] = {
	{.addr = 0x004041f0U, .prod = 0x0000c646U, .disable = 0x00000000U},
	{.addr = 0x00409890U, .prod = 0x0000007fU, .disable = 0x00000000U},
	{.addr = 0x00406000U, .prod = 0x0000c442U, .disable = 0x00000000U},
	{.addr = 0x00405860U, .prod = 0x0000c242U, .disable = 0x00000000U},
	{.addr = 0x00405bf0U, .prod = 0x0000c044U, .disable = 0x00000000U},
	{.addr = 0x004078c0U, .prod = 0x00004242U, .disable = 0x00000000U},
	{.addr = 0x0040590cU, .prod = 0x0000c444U, .disable = 0x00000000U},
	{.addr = 0x00408040U, .prod = 0x0000c443U, .disable = 0x00000000U},
	{.addr = 0x00407000U, .prod = 0x4000c042U, .disable = 0x00000000U},
	{.addr = 0x00422890U, .prod = 0x0000007fU, .disable = 0x00000000U},
	{.addr = 0x00420970U, .prod = 0x0000c242U, .disable = 0x00000000U},
	{.addr = 0x00420e0cU, .prod = 0x0000c444U, .disable = 0x00000000U},
	{.addr = 0x00420898U, .prod = 0x00004242U, .disable = 0x00000000U},
	{.addr = 0x00421498U, .prod = 0x00004242U, .disable = 0x00000000U},
	{.addr = 0x00420500U, .prod = 0x0000c244U, .disable = 0x00000000U},
	{.addr = 0x00420608U, .prod = 0x0000c242U, .disable = 0x00000000U},
	{.addr = 0x00420688U, .prod = 0x0000c242U, .disable = 0x00000000U},
	{.addr = 0x00420718U, .prod = 0x00004042U, .disable = 0x00000000U},
	{.addr = 0x00420828U, .prod = 0x00008442U, .disable = 0x00000000U},
	{.addr = 0x00420bbcU, .prod = 0x0000c242U, .disable = 0x00000000U},
	{.addr = 0x00420c70U, .prod = 0x0000c444U, .disable = 0x00000000U},
	{.addr = 0x00420cf0U, .prod = 0x0000c444U, .disable = 0x00000000U},
	{.addr = 0x00420d70U, .prod = 0x0000c444U, .disable = 0x00000000U},
	{.addr = 0x00420f8cU, .prod = 0x0000c444U, .disable = 0x00000000U},
	{.addr = 0x00421020U, .prod = 0x0000c242U, .disable = 0x00000000U},
	{.addr = 0x00424068U, .prod = 0x00008242U, .disable = 0x00000000U},
	{.addr = 0x00424480U, .prod = 0x00004045U, .disable = 0x00000000U},
	{.addr = 0x00424488U, .prod = 0x00004047U, .disable = 0x00000000U},
	{.addr = 0x00424490U, .prod = 0x00004046U, .disable = 0x00000000U},
	{.addr = 0x00424498U, .prod = 0x00000042U, .disable = 0x00000000U},
	{.addr = 0x004244a0U, .prod = 0x00004047U, .disable = 0x00000000U},
	{.addr = 0x004244a8U, .prod = 0x00000046U, .disable = 0x00000000U},
	{.addr = 0x004244b0U, .prod = 0x00000045U, .disable = 0x00000000U},
	{.addr = 0x00424240U, .prod = 0x00000042U, .disable = 0x00000000U},
	{.addr = 0x00424248U, .prod = 0x00000042U, .disable = 0x00000000U},
	{.addr = 0x00424250U, .prod = 0x00000042U, .disable = 0x00000000U},
	{.addr = 0x00424258U, .prod = 0x00000042U, .disable = 0x00000000U},
	{.addr = 0x00424260U, .prod = 0x00000042U, .disable = 0x00000000U},
	{.addr = 0x00424268U, .prod = 0x00000042U, .disable = 0x00000000U},
	{.addr = 0x00424278U, .prod = 0x00000042U, .disable = 0x00000000U},
	{.addr = 0x00424280U, .prod = 0x00000042U, .disable = 0x00000000U},
	{.addr = 0x00424270U, .prod = 0x00000045U, .disable = 0x00000000U},
	{.addr = 0x00424288U, .prod = 0x00000045U, .disable = 0x00000000U},
	{.addr = 0x00424470U, .prod = 0x0000c444U, .disable = 0x00000000U},
	{.addr = 0x00423e28U, .prod = 0x00008242U, .disable = 0x00000000U},
	{.addr = 0x00423fe8U, .prod = 0x0000c444U, .disable = 0x00000000U},
	{.addr = 0x00423ed0U, .prod = 0x0000c444U, .disable = 0x00000000U},
	{.addr = 0x00423818U, .prod = 0x0000c242U, .disable = 0x00000000U},
	{.addr = 0x00423874U, .prod = 0x0000c242U, .disable = 0x00000000U},
	{.addr = 0x00423898U, .prod = 0x0000c242U, .disable = 0x00000000U},
	{.addr = 0x00423c18U, .prod = 0x0000c242U, .disable = 0x00000000U},
	{.addr = 0x00423c74U, .prod = 0x0000c242U, .disable = 0x00000000U},
	{.addr = 0x00423c98U, .prod = 0x0000c242U, .disable = 0x00000000U},
};

/* blcg ltc */
static const struct gating_desc gb10b_blcg_ltc[] = {
	{.addr = 0x001c6030U, .prod = 0x00000044U, .disable = 0x00000000U},
	{.addr = 0x001c6040U, .prod = 0x00000044U, .disable = 0x00000000U},
	{.addr = 0x001c63e0U, .prod = 0x00000044U, .disable = 0x00000000U},
	{.addr = 0x001c63c8U, .prod = 0x00000044U, .disable = 0x00000000U},
};

/* blcg pmu */
static const struct gating_desc gb10b_blcg_pmu[] = {
	{.addr = 0x008f6a70U, .prod = 0x00000045U, .disable = 0x00000000U},
};

/* blcg Xbar */
static const struct gating_desc gb10b_blcg_xbar[] = {
	{.addr = 0x0013c820U, .prod = 0x0001004aU, .disable = 0x00000000U},
	{.addr = 0x0013ebc4U, .prod = 0x0001004aU, .disable = 0x00000000U},
	{.addr = 0x0013c920U, .prod = 0x0000004aU, .disable = 0x00000000U},
	{.addr = 0x0013cb80U, .prod = 0x00000042U, .disable = 0x00000000U},
	{.addr = 0x0013cb88U, .prod = 0x00000042U, .disable = 0x00000000U},
};

/* blcg fbhub */
static const struct gating_desc gb10b_blcg_fbhub[] = {
	{.addr = 0x008a0110U, .prod = 0x00000270U, .disable = 0x00000000U},
	{.addr = 0x008a17bcU, .prod = 0x00000270U, .disable = 0x00000000U},
	{.addr = 0x008a1d4cU, .prod = 0x00000270U, .disable = 0x00000000U},
};

/* blcg Hshub */
static const struct gating_desc gb10b_blcg_hshub[] = {
};

/* blcg Ctrl */
static const struct gating_desc gb10b_blcg_ctrl[] = {
	{.addr = 0x00b66a28U, .prod = 0x00000040U, .disable = 0x00000000U},
};

/* elcg ce */
static const struct gating_desc gb10b_elcg_ce[] = {
	{.addr = 0x00104044U, .prod = 0x00000001U, .disable = 0x00000000U},
};

/* flcg perf */
static const struct gating_desc gb10b_flcg_perf[] = {
	{.addr = 0x002b4094U, .prod = 0x80000000U, .disable = 0x00000000U},
	{.addr = 0x002b4098U, .prod = 0x80000000U, .disable = 0x00000000U},
	{.addr = 0x002b4094U, .prod = 0x80000000U, .disable = 0x00000000U},
	{.addr = 0x002b4098U, .prod = 0x80000000U, .disable = 0x00000000U},
	{.addr = 0x002a0094U, .prod = 0x80000000U, .disable = 0x00000000U},
	{.addr = 0x002a0098U, .prod = 0x80000000U, .disable = 0x00000000U},
	{.addr = 0x002a0094U, .prod = 0x80000000U, .disable = 0x00000000U},
	{.addr = 0x002a0098U, .prod = 0x80000000U, .disable = 0x00000000U},
	{.addr = 0x002a0494U, .prod = 0x80000000U, .disable = 0x00000000U},
	{.addr = 0x002a0498U, .prod = 0x80000000U, .disable = 0x00000000U},
	{.addr = 0x002a0894U, .prod = 0x80000000U, .disable = 0x00000000U},
	{.addr = 0x002a0898U, .prod = 0x80000000U, .disable = 0x00000000U},
	{.addr = 0x002a0c94U, .prod = 0x80000000U, .disable = 0x00000000U},
	{.addr = 0x002a0c98U, .prod = 0x80000000U, .disable = 0x00000000U},
	{.addr = 0x002aa094U, .prod = 0x80000000U, .disable = 0x00000000U},
	{.addr = 0x002aa098U, .prod = 0x80000000U, .disable = 0x00000000U},
	{.addr = 0x002a4094U, .prod = 0x80000000U, .disable = 0x00000000U},
	{.addr = 0x002a4098U, .prod = 0x80000000U, .disable = 0x00000000U},
	{.addr = 0x002a4094U, .prod = 0x80000000U, .disable = 0x00000000U},
	{.addr = 0x002a4098U, .prod = 0x80000000U, .disable = 0x00000000U},
	{.addr = 0x002a4494U, .prod = 0x80000000U, .disable = 0x00000000U},
	{.addr = 0x002a4498U, .prod = 0x80000000U, .disable = 0x00000000U},
	{.addr = 0x002a4894U, .prod = 0x80000000U, .disable = 0x00000000U},
	{.addr = 0x002a4898U, .prod = 0x80000000U, .disable = 0x00000000U},
	{.addr = 0x002aa494U, .prod = 0x80000000U, .disable = 0x00000000U},
	{.addr = 0x002aa498U, .prod = 0x80000000U, .disable = 0x00000000U},
	{.addr = 0x002b0848U, .prod = 0x80000000U, .disable = 0x00000000U},
	{.addr = 0x002b0848U, .prod = 0x80000000U, .disable = 0x00000000U},
};

/* slcg nvdec */
static const struct gating_desc gb10b_slcg_nvdec_0[] = {
	{.addr = 0x00848134U, .prod = 0x001c0140U, .disable = 0x0003fffeU},
	{.addr = 0x0084b398U, .prod = 0x00000000U, .disable = 0x00000003U},
	{.addr = 0x0084be74U, .prod = 0x00000000U, .disable = 0x0000000fU},
	{.addr = 0x00849328U, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x0084932cU, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x00849950U, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x00849954U, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x0084996cU, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x00849974U, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x00849958U, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x00849970U, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x0084995cU, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x00849960U, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x00849964U, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x00849968U, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x00849340U, .prod = 0x00000001U, .disable = 0x00000000U},
	{.addr = 0x0084997cU, .prod = 0x00000000U, .disable = 0x00007e00U},
};

static const struct gating_desc gb10b_slcg_nvdec_1[] = {
	{.addr = 0x0084c134U, .prod = 0x001c0140U, .disable = 0x0003fffeU},
	{.addr = 0x0084f398U, .prod = 0x00000000U, .disable = 0x00000003U},
	{.addr = 0x0084fe74U, .prod = 0x00000000U, .disable = 0x0000000fU},
	{.addr = 0x0084d328U, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x0084d32cU, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x0084d950U, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x0084d954U, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x0084d96cU, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x0084d974U, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x0084d958U, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x0084d970U, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x0084d95cU, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x0084d960U, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x0084d964U, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x0084d968U, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x0084d340U, .prod = 0x00000001U, .disable = 0x00000000U},
	{.addr = 0x0084d97cU, .prod = 0x00000000U, .disable = 0x00007e00U},
};

/* slcg nvenc */
static const struct gating_desc gb10b_slcg_nvenc_0[] = {
	{.addr = 0x001c8134U, .prod = 0x00180140U, .disable = 0x0003fffeU},
	{.addr = 0x001cb398U, .prod = 0x00000000U, .disable = 0x00000003U},
	{.addr = 0x001c8874U, .prod = 0x00000000U, .disable = 0x0000000fU},
	{.addr = 0x001caf38U, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x001caf3cU, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x001caf40U, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x001c8f24U, .prod = 0x00000000U, .disable = 0x00001ffeU},
	{.addr = 0x001c9200U, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x001c9204U, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x001c9208U, .prod = 0x00000000U, .disable = 0xffffffffU},
};

static const struct gating_desc gb10b_slcg_nvenc_1[] = {
	{.addr = 0x001cc134U, .prod = 0x00180140U, .disable = 0x0003fffeU},
	{.addr = 0x001cf398U, .prod = 0x00000000U, .disable = 0x00000003U},
	{.addr = 0x001cc874U, .prod = 0x00000000U, .disable = 0x0000000fU},
	{.addr = 0x001cef38U, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x001cef3cU, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x001cef40U, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x001ccf24U, .prod = 0x00000000U, .disable = 0x00001ffeU},
	{.addr = 0x001cd200U, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x001cd204U, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x001cd208U, .prod = 0x00000000U, .disable = 0xffffffffU},
};

/* slcg nvjpg */
static const struct gating_desc gb10b_slcg_nvjpg_0[] = {
	{.addr = 0x009c0134U, .prod = 0x00180140U, .disable = 0x0003fffeU},
	{.addr = 0x009c8134U, .prod = 0x00180140U, .disable = 0x0003fffeU},
	{.addr = 0x009c3398U, .prod = 0x00000000U, .disable = 0x00000003U},
	{.addr = 0x009cb398U, .prod = 0x00000000U, .disable = 0x00000003U},
	{.addr = 0x009c0474U, .prod = 0x00000000U, .disable = 0x0000000fU},
	{.addr = 0x009c8474U, .prod = 0x00000000U, .disable = 0x0000000fU},
	{.addr = 0x009c09dcU, .prod = 0x00000000U, .disable = 0x00000002U},
	{.addr = 0x009c89dcU, .prod = 0x00000000U, .disable = 0x00000002U},
};

static const struct gating_desc gb10b_slcg_nvjpg_1[] = {
	{.addr = 0x009c8134U, .prod = 0x00180140U, .disable = 0x0003fffeU},
	{.addr = 0x009c3398U, .prod = 0x00000000U, .disable = 0x00000003U},
	{.addr = 0x009cb398U, .prod = 0x00000000U, .disable = 0x00000003U},
	{.addr = 0x009c0474U, .prod = 0x00000000U, .disable = 0x0000000fU},
	{.addr = 0x009c8474U, .prod = 0x00000000U, .disable = 0x0000000fU},
	{.addr = 0x009c09dcU, .prod = 0x00000000U, .disable = 0x00000002U},
	{.addr = 0x009c89dcU, .prod = 0x00000000U, .disable = 0x00000002U},
};

/* slcg ofa */
static const struct gating_desc gb10b_slcg_ofa_0[] = {
	{.addr = 0x00846178U, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x008461a0U, .prod = 0x00000000U, .disable = 0xffffffffU},
	{.addr = 0x00846c04U, .prod = 0x00000000U, .disable = 0x00000002U},
	{.addr = 0x00844134U, .prod = 0x00180140U, .disable = 0x0003fffeU},
	{.addr = 0x00844b98U, .prod = 0x00000000U, .disable = 0x00000003U},
	{.addr = 0x00844474U, .prod = 0x00000000U, .disable = 0x0000000fU},
};

/* blcg nvdec */
static const struct gating_desc gb10b_blcg_nvdec_0[] = {
	{.addr = 0x00849320U, .prod = 0x00080042U, .disable = 0x00000000U},
};

static const struct gating_desc gb10b_blcg_nvdec_1[] = {
	{.addr = 0x0084d320U, .prod = 0x00080042U, .disable = 0x00000000U},
};

/* blcg nvenc */
static const struct gating_desc gb10b_blcg_nvenc_0[] = {
	{.addr = 0x001c8f20U, .prod = 0x000ac042U, .disable = 0x00000000U},
};

static const struct gating_desc gb10b_blcg_nvenc_1[] = {
	{.addr = 0x001ccf20U, .prod = 0x000ac042U, .disable = 0x00000000U},
};

/* blcg nvjpg */
static const struct gating_desc gb10b_blcg_nvjpg_0[] = {
	{.addr = 0x009c09d8U, .prod = 0x00000042U, .disable = 0x00000000U},
};

static const struct gating_desc gb10b_blcg_nvjpg_1[] = {
	{.addr = 0x009c09d8U, .prod = 0x00000042U, .disable = 0x00000000U},
	{.addr = 0x009c89d8U, .prod = 0x00000042U, .disable = 0x00000000U},
};

/* blcg ofa */
static const struct gating_desc gb10b_blcg_ofa_0[] = {
	{.addr = 0x00846c00U, .prod = 0x00060042U, .disable = 0x00000000U},
};

/* slcg xal ep */
static const struct gating_desc gb10b_slcg_xal_ep[] = {
	{.addr = 0x0010fa04U, .prod = 0x00000000U, .disable = 0x01fffffcU},
};

/* blcg xal ep */
static const struct gating_desc gb10b_blcg_xal_ep[] = {
	{.addr = 0x0010fa00U, .prod = 0x000000c2U, .disable = 0x00000000U},
};

/* inline functions */
void gb10b_slcg_bus_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_bus)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_SLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_slcg_bus[i].addr;
			u32 val = prod ? gb10b_slcg_bus[i].prod :
					 gb10b_slcg_bus[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_slcg_bus_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_slcg_bus));
}

const struct gating_desc *gb10b_slcg_bus_get_gating_prod(void)
{
	return gb10b_slcg_bus;
}

void gb10b_slcg_ce2_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_ce2)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_SLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_slcg_ce2[i].addr;
			u32 val = prod ? gb10b_slcg_ce2[i].prod :
					 gb10b_slcg_ce2[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_slcg_ce2_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_slcg_ce2));
}

const struct gating_desc *gb10b_slcg_ce2_get_gating_prod(void)
{
	return gb10b_slcg_ce2;
}

void gb10b_slcg_chiplet_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_chiplet)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_SLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_slcg_chiplet[i].addr;
			u32 val = prod ? gb10b_slcg_chiplet[i].prod :
					 gb10b_slcg_chiplet[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_slcg_chiplet_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_slcg_chiplet));
}

const struct gating_desc *gb10b_slcg_chiplet_get_gating_prod(void)
{
	return gb10b_slcg_chiplet;
}

void gb10b_slcg_fb_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_fb)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_SLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_slcg_fb[i].addr;
			u32 val = prod ? gb10b_slcg_fb[i].prod :
					 gb10b_slcg_fb[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_slcg_fb_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_slcg_fb));
}

const struct gating_desc *gb10b_slcg_fb_get_gating_prod(void)
{
	return gb10b_slcg_fb;
}

void gb10b_slcg_runlist_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_runlist)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_SLCG)) {
		for (i = 0U; i < size; i++) {
			struct nvgpu_fifo *f = &g->fifo;
			struct nvgpu_runlist *runlist;
			u32 j, runlist_pri_base;
			u32 reg = gb10b_slcg_runlist[i].addr;
			u32 val = prod ? gb10b_slcg_runlist[i].prod :
					 gb10b_slcg_runlist[i].disable;
			for (j = 0U; j < f->num_runlists; j++) {
				runlist = &f->active_runlists[j];
				runlist_pri_base = runlist->runlist_pri_base;
				nvgpu_writel(g, nvgpu_safe_add_u32(reg, runlist_pri_base), val);
			}
		}
	}
}

u32 gb10b_slcg_runlist_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_slcg_runlist));
}

const struct gating_desc *gb10b_slcg_runlist_get_gating_prod(void)
{
	return gb10b_slcg_runlist;
}

void gb10b_slcg_gr_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_gr)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_SLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_slcg_gr[i].addr;
			u32 val = prod ? gb10b_slcg_gr[i].prod :
					 gb10b_slcg_gr[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_slcg_gr_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_slcg_gr));
}

const struct gating_desc *gb10b_slcg_gr_get_gating_prod(void)
{
	return gb10b_slcg_gr;
}

void gb10b_slcg_ltc_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_ltc)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_SLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_slcg_ltc[i].addr;
			u32 val = prod ? gb10b_slcg_ltc[i].prod :
					 gb10b_slcg_ltc[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_slcg_ltc_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_slcg_ltc));
}

const struct gating_desc *gb10b_slcg_ltc_get_gating_prod(void)
{
	return gb10b_slcg_ltc;
}

void gb10b_slcg_perf_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_perf)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_SLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_slcg_perf[i].addr;
			u32 val = prod ? gb10b_slcg_perf[i].prod :
					 gb10b_slcg_perf[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_slcg_perf_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_slcg_perf));
}

const struct gating_desc *gb10b_slcg_perf_get_gating_prod(void)
{
	return gb10b_slcg_perf;
}

void gb10b_slcg_priring_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_priring)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_SLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_slcg_priring[i].addr;
			u32 val = prod ? gb10b_slcg_priring[i].prod :
					 gb10b_slcg_priring[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_slcg_priring_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_slcg_priring));
}

const struct gating_desc *gb10b_slcg_priring_get_gating_prod(void)
{
	return gb10b_slcg_priring;
}

void gb10b_slcg_fbhub_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_fbhub)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_SLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_slcg_fbhub[i].addr;
			u32 val = prod ? gb10b_slcg_fbhub[i].prod :
					 gb10b_slcg_fbhub[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_slcg_fbhub_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_slcg_fbhub));
}

const struct gating_desc *gb10b_slcg_fbhub_get_gating_prod(void)
{
	return gb10b_slcg_fbhub;
}

void gb10b_slcg_rs_ctrl_fbp_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_rs_ctrl_fbp)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_SLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_slcg_rs_ctrl_fbp[i].addr;
			u32 val = prod ? gb10b_slcg_rs_ctrl_fbp[i].prod :
					 gb10b_slcg_rs_ctrl_fbp[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_slcg_rs_ctrl_fbp_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_slcg_rs_ctrl_fbp));
}

const struct gating_desc *gb10b_slcg_rs_ctrl_fbp_get_gating_prod(void)
{
	return gb10b_slcg_rs_ctrl_fbp;
}

void gb10b_slcg_rs_ctrl_gpc_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_rs_ctrl_gpc)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_SLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_slcg_rs_ctrl_gpc[i].addr;
			u32 val = prod ? gb10b_slcg_rs_ctrl_gpc[i].prod :
					 gb10b_slcg_rs_ctrl_gpc[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_slcg_rs_ctrl_gpc_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_slcg_rs_ctrl_gpc));
}

const struct gating_desc *gb10b_slcg_rs_ctrl_gpc_get_gating_prod(void)
{
	return gb10b_slcg_rs_ctrl_gpc;
}

void gb10b_slcg_rs_ctrl_sys_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_rs_ctrl_sys)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_SLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_slcg_rs_ctrl_sys[i].addr;
			u32 val = prod ? gb10b_slcg_rs_ctrl_sys[i].prod :
					 gb10b_slcg_rs_ctrl_sys[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_slcg_rs_ctrl_sys_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_slcg_rs_ctrl_sys));
}

const struct gating_desc *gb10b_slcg_rs_ctrl_sys_get_gating_prod(void)
{
	return gb10b_slcg_rs_ctrl_sys;
}

void gb10b_slcg_rs_fbp_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_rs_fbp)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_SLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_slcg_rs_fbp[i].addr;
			u32 val = prod ? gb10b_slcg_rs_fbp[i].prod :
					 gb10b_slcg_rs_fbp[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_slcg_rs_fbp_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_slcg_rs_fbp));
}

const struct gating_desc *gb10b_slcg_rs_fbp_get_gating_prod(void)
{
	return gb10b_slcg_rs_fbp;
}

void gb10b_slcg_rs_gpc_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_rs_gpc)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_SLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_slcg_rs_gpc[i].addr;
			u32 val = prod ? gb10b_slcg_rs_gpc[i].prod :
					 gb10b_slcg_rs_gpc[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_slcg_rs_gpc_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_slcg_rs_gpc));
}

const struct gating_desc *gb10b_slcg_rs_gpc_get_gating_prod(void)
{
	return gb10b_slcg_rs_gpc;
}

void gb10b_slcg_rs_sys_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_rs_sys)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_SLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_slcg_rs_sys[i].addr;
			u32 val = prod ? gb10b_slcg_rs_sys[i].prod :
					 gb10b_slcg_rs_sys[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_slcg_rs_sys_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_slcg_rs_sys));
}

const struct gating_desc *gb10b_slcg_rs_sys_get_gating_prod(void)
{
	return gb10b_slcg_rs_sys;
}

void gb10b_slcg_timer_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_timer)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_SLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_slcg_timer[i].addr;
			u32 val = prod ? gb10b_slcg_timer[i].prod :
					 gb10b_slcg_timer[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_slcg_timer_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_slcg_timer));
}

const struct gating_desc *gb10b_slcg_timer_get_gating_prod(void)
{
	return gb10b_slcg_timer;
}

void gb10b_slcg_pmu_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_pmu)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_SLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_slcg_pmu[i].addr;
			u32 val = prod ? gb10b_slcg_pmu[i].prod :
					 gb10b_slcg_pmu[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_slcg_pmu_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_slcg_pmu));
}

const struct gating_desc *gb10b_slcg_pmu_get_gating_prod(void)
{
	return gb10b_slcg_pmu;
}

void gb10b_blcg_nvdec_load_gating_prod(struct gk20a *g,
	u32 inst_id, bool prod)
{
	u32 i;
	u32 size;

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_BLCG)) {
		if(inst_id == 0) {
			size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_blcg_nvdec_0)
							/ GATING_DESC_SIZE);
			for (i = 0U; i < size; i++) {
				u32 reg = gb10b_blcg_nvdec_0[i].addr;
				u32 val = prod ? gb10b_blcg_nvdec_0[i].prod :
					 gb10b_blcg_nvdec_0[i].disable;
				nvgpu_writel(g, reg, val);
			}
		} else {
			size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_blcg_nvdec_1)
							/ GATING_DESC_SIZE);

			for (i = 0U; i < size; i++) {
				u32 reg = gb10b_blcg_nvdec_1[i].addr;
				u32 val = prod ? gb10b_blcg_nvdec_1[i].prod :
					 gb10b_blcg_nvdec_1[i].disable;
				nvgpu_writel(g, reg, val);
			}
		}
	}
}

void gb10b_blcg_nvenc_load_gating_prod(struct gk20a *g,
	u32 inst_id, bool prod)
{
	u32 i;
	u32 size;

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_BLCG)) {
		if(inst_id == 0) {
			size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_blcg_nvenc_0)
							/ GATING_DESC_SIZE);
			for (i = 0U; i < size; i++) {
				u32 reg = gb10b_blcg_nvenc_0[i].addr;
				u32 val = prod ? gb10b_blcg_nvenc_0[i].prod :
					 gb10b_blcg_nvenc_0[i].disable;
				nvgpu_writel(g, reg, val);
			}
		} else {
			size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_blcg_nvenc_1)
							/ GATING_DESC_SIZE);

			for (i = 0U; i < size; i++) {
				u32 reg = gb10b_blcg_nvenc_1[i].addr;
				u32 val = prod ? gb10b_blcg_nvenc_1[i].prod :
					 gb10b_blcg_nvenc_1[i].disable;
				nvgpu_writel(g, reg, val);
			}
		}
	}
}

void gb10b_blcg_nvjpg_load_gating_prod(struct gk20a *g,
	u32 inst_id, bool prod)
{
	u32 i;
	u32 size;

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_BLCG)) {
		if(inst_id == 0) {
			size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_blcg_nvjpg_0)
							/ GATING_DESC_SIZE);
			for (i = 0U; i < size; i++) {
				u32 reg = gb10b_blcg_nvjpg_0[i].addr;
				u32 val = prod ? gb10b_blcg_nvjpg_0[i].prod :
					 gb10b_blcg_nvjpg_0[i].disable;
				nvgpu_writel(g, reg, val);
			}
		} else {
			size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_blcg_nvjpg_1)
							/ GATING_DESC_SIZE);

			for (i = 0U; i < size; i++) {
				u32 reg = gb10b_blcg_nvjpg_1[i].addr;
				u32 val = prod ? gb10b_blcg_nvjpg_1[i].prod :
					 gb10b_blcg_nvjpg_1[i].disable;
				nvgpu_writel(g, reg, val);
			}
		}
	}
}

void gb10b_blcg_ofa_load_gating_prod(struct gk20a *g,
	u32 inst_id, bool prod)
{
	u32 i;
	u32 size;

	nvgpu_assert(inst_id == 0U);
	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_BLCG)) {
		size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_blcg_ofa_0)
						/ GATING_DESC_SIZE);
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_blcg_ofa_0[i].addr;
			u32 val = prod ? gb10b_blcg_ofa_0[i].prod :
				 gb10b_blcg_ofa_0[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

void gb10b_slcg_nvdec_load_gating_prod(struct gk20a *g,
	u32 inst_id, bool prod)
{
	u32 i;
	u32 size;

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_SLCG)) {
		if(inst_id == 0) {
			size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_nvdec_0)
							/ GATING_DESC_SIZE);

			for (i = 0U; i < size; i++) {
				u32 reg = gb10b_slcg_nvdec_0[i].addr;
				u32 val = prod ? gb10b_slcg_nvdec_0[i].prod :
					 gb10b_slcg_nvdec_0[i].disable;
				nvgpu_writel(g, reg, val);
			}
		} else {
			size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_nvdec_1)
							/ GATING_DESC_SIZE);

			for (i = 0U; i < size; i++) {
				u32 reg = gb10b_slcg_nvdec_1[i].addr;
				u32 val = prod ? gb10b_slcg_nvdec_1[i].prod :
					 gb10b_slcg_nvdec_0[i].disable;
				nvgpu_writel(g, reg, val);
			}
		}
	}
}

void gb10b_slcg_nvenc_load_gating_prod(struct gk20a *g,
	u32 inst_id, bool prod)
{
	u32 i;
	u32 size;

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_SLCG)) {
		if(inst_id == 0) {
			size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_nvenc_0)
							/ GATING_DESC_SIZE);

			for (i = 0U; i < size; i++) {
				u32 reg = gb10b_slcg_nvenc_0[i].addr;
				u32 val = prod ? gb10b_slcg_nvenc_0[i].prod :
					 gb10b_slcg_nvenc_0[i].disable;
				nvgpu_writel(g, reg, val);
			}
		} else {
			size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_nvenc_1)
							/ GATING_DESC_SIZE);

			for (i = 0U; i < size; i++) {
				u32 reg = gb10b_slcg_nvenc_1[i].addr;
				u32 val = prod ? gb10b_slcg_nvenc_1[i].prod :
					 gb10b_slcg_nvenc_0[i].disable;
				nvgpu_writel(g, reg, val);
			}
		}
	}
}

void gb10b_slcg_nvjpg_load_gating_prod(struct gk20a *g,
	u32 inst_id, bool prod)
{
	u32 i;
	u32 size;

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_SLCG)) {
		if(inst_id == 0) {
			size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_nvjpg_0)
							/ GATING_DESC_SIZE);

			for (i = 0U; i < size; i++) {
				u32 reg = gb10b_slcg_nvjpg_0[i].addr;
				u32 val = prod ? gb10b_slcg_nvjpg_0[i].prod :
					 gb10b_slcg_nvjpg_0[i].disable;
				nvgpu_writel(g, reg, val);
			}
		} else {
			size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_nvjpg_1)
							/ GATING_DESC_SIZE);

			for (i = 0U; i < size; i++) {
				u32 reg = gb10b_slcg_nvjpg_1[i].addr;
				u32 val = prod ? gb10b_slcg_nvjpg_1[i].prod :
					 gb10b_slcg_nvjpg_0[i].disable;
				nvgpu_writel(g, reg, val);
			}
		}
	}
}

void gb10b_slcg_ofa_load_gating_prod(struct gk20a *g,
	u32 inst_id, bool prod)
{
	u32 i;
	u32 size;

	nvgpu_assert(inst_id == 0U);
	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_SLCG)) {
		size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_ofa_0)
							/ GATING_DESC_SIZE);
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_slcg_ofa_0[i].addr;
			u32 val = prod ? gb10b_slcg_ofa_0[i].prod :
				 gb10b_slcg_ofa_0[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

void gb10b_blcg_xal_ep_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_blcg_xal_ep)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_BLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_blcg_xal_ep[i].addr;
			u32 val = prod ? gb10b_blcg_xal_ep[i].prod :
					 gb10b_blcg_xal_ep[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_blcg_xal_ep_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_blcg_xal_ep));
}

const struct gating_desc *gb10b_blcg_xal_ep_get_gating_prod(void)
{
	return gb10b_blcg_xal_ep;
}

void gb10b_slcg_xal_ep_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_xal_ep)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_SLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_slcg_xal_ep[i].addr;
			u32 val = prod ? gb10b_slcg_xal_ep[i].prod :
					 gb10b_slcg_xal_ep[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_slcg_xal_ep_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_slcg_xal_ep));
}

const struct gating_desc *gb10b_slcg_xal_ep_get_gating_prod(void)
{
	return gb10b_slcg_xal_ep;
}

void gb10b_slcg_xbar_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_xbar)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_SLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_slcg_xbar[i].addr;
			u32 val = prod ? gb10b_slcg_xbar[i].prod :
					 gb10b_slcg_xbar[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_slcg_xbar_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_slcg_xbar));
}

const struct gating_desc *gb10b_slcg_xbar_get_gating_prod(void)
{
	return gb10b_slcg_xbar;
}

void gb10b_slcg_hshub_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_hshub)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_SLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_slcg_hshub[i].addr;
			u32 val = prod ? gb10b_slcg_hshub[i].prod :
					 gb10b_slcg_hshub[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_slcg_hshub_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_slcg_hshub));
}

const struct gating_desc *gb10b_slcg_hshub_get_gating_prod(void)
{
	return gb10b_slcg_hshub;
}

void gb10b_slcg_ctrl_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_ctrl)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_SLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_slcg_ctrl[i].addr;
			u32 val = prod ? gb10b_slcg_ctrl[i].prod :
					 gb10b_slcg_ctrl[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_slcg_ctrl_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_slcg_ctrl));
}

const struct gating_desc *gb10b_slcg_ctrl_get_gating_prod(void)
{
	return gb10b_slcg_ctrl;
}

void gb10b_slcg_gsp_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_slcg_gsp)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_SLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_slcg_gsp[i].addr;
			u32 val = prod ? gb10b_slcg_gsp[i].prod :
					 gb10b_slcg_gsp[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_slcg_gsp_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_slcg_gsp));
}

const struct gating_desc *gb10b_slcg_gsp_get_gating_prod(void)
{
	return gb10b_slcg_gsp;
}

void gb10b_blcg_bus_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_blcg_bus)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_BLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_blcg_bus[i].addr;
			u32 val = prod ? gb10b_blcg_bus[i].prod :
					 gb10b_blcg_bus[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_blcg_bus_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_blcg_bus));
}

const struct gating_desc *gb10b_blcg_bus_get_gating_prod(void)
{
	return gb10b_blcg_bus;
}

void gb10b_blcg_ce_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_blcg_ce)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_BLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_blcg_ce[i].addr;
			u32 val = prod ? gb10b_blcg_ce[i].prod :
					 gb10b_blcg_ce[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_blcg_ce_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_blcg_ce));
}

const struct gating_desc *gb10b_blcg_ce_get_gating_prod(void)
{
	return gb10b_blcg_ce;
}

void gb10b_blcg_fb_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_blcg_fb)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_BLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_blcg_fb[i].addr;
			u32 val = prod ? gb10b_blcg_fb[i].prod :
					 gb10b_blcg_fb[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_blcg_fb_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_blcg_fb));
}

const struct gating_desc *gb10b_blcg_fb_get_gating_prod(void)
{
	return gb10b_blcg_fb;
}

void gb10b_blcg_runlist_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_blcg_runlist)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_BLCG)) {
		for (i = 0U; i < size; i++) {
			struct nvgpu_fifo *f = &g->fifo;
			struct nvgpu_runlist *runlist;
			u32 j, runlist_pri_base;
			u32 reg = gb10b_blcg_runlist[i].addr;
			u32 val = prod ? gb10b_blcg_runlist[i].prod :
					 gb10b_blcg_runlist[i].disable;
			for (j = 0U; j < f->num_runlists; j++) {
				runlist = &f->active_runlists[j];
				runlist_pri_base = runlist->runlist_pri_base;
				nvgpu_writel(g, nvgpu_safe_add_u32(reg, runlist_pri_base), val);
			}
		}
	}
}

u32 gb10b_blcg_runlist_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_blcg_runlist));
}

const struct gating_desc *gb10b_blcg_runlist_get_gating_prod(void)
{
	return gb10b_blcg_runlist;
}

void gb10b_blcg_gr_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_blcg_gr)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_BLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_blcg_gr[i].addr;
			u32 val = prod ? gb10b_blcg_gr[i].prod :
					 gb10b_blcg_gr[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_blcg_gr_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_blcg_gr));
}

const struct gating_desc *gb10b_blcg_gr_get_gating_prod(void)
{
	return gb10b_blcg_gr;
}

void gb10b_blcg_ltc_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_blcg_ltc)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_BLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_blcg_ltc[i].addr;
			u32 val = prod ? gb10b_blcg_ltc[i].prod :
					 gb10b_blcg_ltc[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_blcg_ltc_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_blcg_ltc));
}

const struct gating_desc *gb10b_blcg_ltc_get_gating_prod(void)
{
	return gb10b_blcg_ltc;
}

void gb10b_blcg_pmu_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_blcg_pmu)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_BLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_blcg_pmu[i].addr;
			u32 val = prod ? gb10b_blcg_pmu[i].prod :
					 gb10b_blcg_pmu[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_blcg_pmu_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_blcg_pmu));
}

const struct gating_desc *gb10b_blcg_pmu_get_gating_prod(void)
{
	return gb10b_blcg_pmu;
}

void gb10b_blcg_xbar_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_blcg_xbar)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_BLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_blcg_xbar[i].addr;
			u32 val = prod ? gb10b_blcg_xbar[i].prod :
					 gb10b_blcg_xbar[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_blcg_xbar_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_blcg_xbar));
}

const struct gating_desc *gb10b_blcg_xbar_get_gating_prod(void)
{
	return gb10b_blcg_xbar;
}

void gb10b_blcg_fbhub_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_blcg_fbhub)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_BLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_blcg_fbhub[i].addr;
			u32 val = prod ? gb10b_blcg_fbhub[i].prod :
					 gb10b_blcg_fbhub[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_blcg_fbhub_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_blcg_fbhub));
}

const struct gating_desc *gb10b_blcg_fbhub_get_gating_prod(void)
{
	return gb10b_blcg_fbhub;
}

void gb10b_blcg_hshub_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_blcg_hshub)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_BLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_blcg_hshub[i].addr;
			u32 val = prod ? gb10b_blcg_hshub[i].prod :
					 gb10b_blcg_hshub[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_blcg_hshub_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_blcg_hshub));
}

const struct gating_desc *gb10b_blcg_hshub_get_gating_prod(void)
{
	return gb10b_blcg_hshub;
}

void gb10b_blcg_ctrl_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_blcg_ctrl)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_BLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_blcg_ctrl[i].addr;
			u32 val = prod ? gb10b_blcg_ctrl[i].prod :
					 gb10b_blcg_ctrl[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_blcg_ctrl_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_blcg_ctrl));
}

const struct gating_desc *gb10b_blcg_ctrl_get_gating_prod(void)
{
	return gb10b_blcg_ctrl;
}

void gb10b_elcg_ce_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_elcg_ce)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_ELCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_elcg_ce[i].addr;
			u32 val = prod ? gb10b_elcg_ce[i].prod :
					 gb10b_elcg_ce[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_elcg_ce_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_elcg_ce));
}

const struct gating_desc *gb10b_elcg_ce_get_gating_prod(void)
{
	return gb10b_elcg_ce;
}

void gb10b_flcg_perf_load_gating_prod(struct gk20a *g,
	bool prod)
{
	u32 i;
	u32 size = nvgpu_safe_cast_u64_to_u32(sizeof(gb10b_flcg_perf)
							/ GATING_DESC_SIZE);

	if (nvgpu_is_enabled(g, NVGPU_GPU_CAN_FLCG)) {
		for (i = 0U; i < size; i++) {
			u32 reg = gb10b_flcg_perf[i].addr;
			u32 val = prod ? gb10b_flcg_perf[i].prod :
					 gb10b_flcg_perf[i].disable;
			nvgpu_writel(g, reg, val);
		}
	}
}

u32 gb10b_flcg_perf_gating_prod_size(void)
{
	return nvgpu_safe_cast_u64_to_u32(ARRAY_SIZE(gb10b_flcg_perf));
}

const struct gating_desc *gb10b_flcg_perf_get_gating_prod(void)
{
	return gb10b_flcg_perf;
}

